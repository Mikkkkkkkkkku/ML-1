import tensorflow as tf
import sys
import os

print("=" * 60)
print("TensorFlow å®‰è£…éªŒè¯")
print("=" * 60)

# è®¾ç½® CUDA ç¯å¢ƒ
cuda_path = "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8"
os.environ['CUDA_PATH'] = cuda_path
os.environ['PATH'] = f"{cuda_path}\\bin;{cuda_path}\\libnvvp;{os.environ['PATH']}"

print(f"Python ç‰ˆæœ¬: {sys.version}")
print(f"TensorFlow ç‰ˆæœ¬: {tf.__version__}")
print(f"TensorFlow è·¯å¾„: {tf.__file__}")

print(f"\næ„å»ºä¿¡æ¯:")
print(f"  ä½¿ç”¨ CUDA æ„å»º: {tf.test.is_built_with_cuda()}")
print(f"  ä½¿ç”¨ GPU æ„å»º: {tf.test.is_built_with_gpu_support()}")

print(f"\nè®¾å¤‡åˆ—è¡¨:")
gpu_devices = tf.config.list_physical_devices('GPU')
cpu_devices = tf.config.list_physical_devices('CPU')
print(f"  GPU è®¾å¤‡: {gpu_devices}")
print(f"  CPU è®¾å¤‡: {cpu_devices}")

if gpu_devices:
    print("\nğŸ‰ GPU æ”¯æŒå·²å¯ç”¨ï¼æ­£åœ¨æµ‹è¯•æ€§èƒ½...")
    # æµ‹è¯• GPU æ€§èƒ½
    with tf.device('/GPU:0'):
        import time

        start_time = time.time()

        # åˆ›å»ºè¾ƒå¤§çš„è®¡ç®—ä»»åŠ¡
        a = tf.random.normal([2000, 2000])
        b = tf.random.normal([2000, 2000])
        c = tf.matmul(a, b)

        end_time = time.time()
        print(f"âœ… GPU çŸ©é˜µä¹˜æ³•å®Œæˆ!")
        print(f"   è®¡ç®—æ—¶é—´: {end_time - start_time:.2f} ç§’")
        print(f"   ç»“æœå½¢çŠ¶: {c.shape}")

        # æ˜¾ç¤º GPU ä¿¡æ¯
        for i, gpu in enumerate(gpu_devices):
            print(f"   GPU {i}: {gpu}")
else:
    print("\nâŒ æœªæ£€æµ‹åˆ° GPU è®¾å¤‡")

# æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨è®¾å¤‡
from tensorflow.python.client import device_lib

print(f"\næ‰€æœ‰è®¡ç®—è®¾å¤‡:")
devices = device_lib.list_local_devices()
for device in devices:
    print(f"  - {device.name} | {device.device_type} | å†…å­˜: {device.memory_limit / 1024 ** 3:.1f} GB")